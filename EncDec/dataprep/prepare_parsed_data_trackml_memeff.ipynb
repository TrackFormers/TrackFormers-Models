{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4259a5",
   "metadata": {},
   "source": [
    "# Data Preparation Script\n",
    "\n",
    "This script is responsible for preparing data to be read by the written framework. It converts data from the `trackml` format to a format that the framework can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255b6098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from trackml.dataset import load_event\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(1, './../../')\n",
    "from utils import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a0d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data_dir = \"/Users/zefwolffs/Documents/phd/tracking/trackformers/data/experiment_3d_noisy-100k-events-50-to-100-helical-tracks/parsed_data_memeff_1m\"\n",
    "eventrange = range(21100, 21102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ed21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = None\n",
    "\n",
    "x_max = None\n",
    "x_min = None\n",
    "y_max = None\n",
    "y_min = None\n",
    "z_max = None\n",
    "z_min = None\n",
    "\n",
    "for event_number in eventrange:\n",
    "    hits_event = load_event(f'./../../data/trackml/train_sample/event0000{event_number}', parts=[\"hits\"])[0]\n",
    "    hits_event = hits_event.loc[hits_event['volume_id'].isin([7, 8, 9])]\n",
    "    if x_max is None or hits_event[\"x\"].max() > x_max:\n",
    "        x_max = hits_event[\"x\"].max()\n",
    "    if x_min is None or hits_event[\"x\"].min() < x_min:\n",
    "        x_min = hits_event[\"x\"].min()\n",
    "    if y_max is None or hits_event[\"y\"].max() > y_max:\n",
    "        y_max = hits_event[\"y\"].max()\n",
    "    if y_min is None or hits_event[\"y\"].min() < y_min:\n",
    "        y_min = hits_event[\"y\"].min()\n",
    "    if z_max is None or hits_event[\"z\"].max() > z_max:\n",
    "        z_max = hits_event[\"z\"].max()\n",
    "    if z_min is None or hits_event[\"z\"].min() < z_min:\n",
    "        z_min = hits_event[\"z\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd0e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalizer(x_min, x_max, y_min, y_max, z_min, z_max)\n",
    "extrema = {\"dim_1_min\": x_min,\"dim_1_max\": x_max,\"dim_2_min\": y_min,\"dim_2_max\": y_max,\"dim_3_min\": z_min,\"dim_3_max\": z_max}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "381e7900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16 390000\n",
      "float16 1000944\n",
      "event 21100 done.\n",
      "float16 780000\n",
      "float16 1763874\n",
      "event 21101 done.\n"
     ]
    }
   ],
   "source": [
    "max_size_tracks = 20\n",
    "max_size_hits = 65000\n",
    "\n",
    "tracks = np.zeros((0, max_size_tracks + 1, 3), dtype=np.float16)\n",
    "hits = np.zeros((0, 65000, 3), dtype=np.float16)\n",
    "track_event_map = np.zeros((0), dtype=np.int32) # Event id per track\n",
    "\n",
    "event_i = 0\n",
    "\n",
    "for event_number in eventrange:\n",
    "    hits_event, truth_event = load_event(f'./../../data/trackml/train_sample/event0000{event_number}', parts=[\"hits\", \"truth\"])\n",
    "    df_event = pd.merge(hits_event, truth_event, on=\"hit_id\")\n",
    "    del hits_event, truth_event\n",
    "    df_event = df_event.loc[df_event['volume_id'].isin([7, 8, 9])]\n",
    "    df_event[\"x\"], df_event[\"y\"], df_event[\"z\"] = norm.normalize(df_event[\"x\"], df_event[\"y\"], df_event[\"z\"])\n",
    "    \n",
    "    tracks_event = np.zeros((df_event[\"particle_id\"].nunique() - 1, max_size_tracks + 1, 3), dtype=np.float16) # n_tracks, n_hits_per_track, n_dims_per_hit\n",
    "    particle_ids = df_event[\"particle_id\"].unique()\n",
    "    particle_ids = np.delete(particle_ids, np.where(particle_ids == 0), axis=0)\n",
    "    for i, unique_particle_id in enumerate(particle_ids):\n",
    "        if unique_particle_id == 0:\n",
    "            i -= 1\n",
    "            continue\n",
    "        track_coords = df_event[df_event[\"particle_id\"] == unique_particle_id][[\"x\", \"y\", \"z\"]].to_numpy(dtype=np.float16)\n",
    "        track = np.pad(track_coords, ((1, max_size_tracks - track_coords.shape[0]), (0, 0)), mode='constant', constant_values=0)\n",
    "        track[0, :] = [0, 0, 0.5]\n",
    "        track[track_coords.shape[0], :] = [0.1,0,0.5]\n",
    "        tracks_event[i, :, :] = track\n",
    "        track_event_map = np.append(track_event_map, event_i)\n",
    "    \n",
    "    event_i += 1\n",
    "    hits_event = df_event[[\"x\", \"y\", \"z\"]].to_numpy(dtype=np.float16)\n",
    "\n",
    "    if hits_event.shape[1] > 65000:\n",
    "        continue\n",
    "    \n",
    "    hits_event = np.expand_dims(hits_event, axis=0)\n",
    "    hits_event = np.pad(hits_event, ((0, 0), (0, 65000 - hits_event.shape[1]), (0, 0)), mode='constant', constant_values=0)\n",
    "    \n",
    "    hits = np.concatenate((hits, hits_event), axis=0)\n",
    "    tracks = np.concatenate((tracks, tracks_event), axis=0)\n",
    "        \n",
    "    print(hits.dtype, hits.nbytes)\n",
    "    print(tracks.dtype, tracks.nbytes)\n",
    "\n",
    "    print(f\"event {event_number} done.\")\n",
    "    del hits_event, tracks_event, df_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae0eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(parsed_data_dir + \"extrema.json\", 'w') as fp:\n",
    "    json.dump(extrema, fp)\n",
    "np.save(parsed_data_dir + \"tracks\", tracks)\n",
    "np.save(parsed_data_dir + \"hits\", hits)\n",
    "np.save(parsed_data_dir + \"track_event_map\", track_event_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
